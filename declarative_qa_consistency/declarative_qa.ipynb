{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import translate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_file = json.load(open(\"../silver_facts.json\"))\n",
    "t_qa = translate_text(json_file)\n",
    "\n",
    "\n",
    "with open('examples.txt', 'w') as f:\n",
    "    for qa in t_qa:\n",
    "        q, a = qa\n",
    "        f.write(q)\n",
    "        f.write('\\n')\n",
    "        f.write(a)\n",
    "        f.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy_conll import init_parser\n",
    "\n",
    "\n",
    "# Initialise English parser, already including the ConllFormatter as a pipeline component.\n",
    "# Indicate that we want to get the CoNLL headers in the string output.\n",
    "# `use_gpu` and `verbose` are specific to stanza (and stanfordnlp). These keywords arguments\n",
    "# are passed onto their Pipeline() initialisation\n",
    "nlp = init_parser(\"en_core_web_sm\",\n",
    "                  \"spacy\",\n",
    "                  include_headers=True)\n",
    "\n",
    "def convert_conll(s):\n",
    "    out = nlp(s)._.conll_str\n",
    "    out = out.split('\\n')[2:-1]\n",
    "    out = '\\n'.join(out) + '\\n\\n'\n",
    "    out = out.replace('ROOT', 'root')\n",
    "    return out\n",
    "\n",
    "\n",
    "# with open('examples.txt', 'r') as f_in:\n",
    "#     with open('examples.conllu', 'w') as f_out:\n",
    "#         for line in f_in:\n",
    "#             x = convert_conll(line)\n",
    "#             tmp = x.split('\\n')\n",
    "#             x = x.split('\\n')[3:-4]\n",
    "#             x = '\\n'.join(x)\n",
    "#             f_out.write(x)\n",
    "#             f_out.write('\\n')\n",
    "#             f_out.write('\\n')\n",
    "\n",
    "\n",
    "with open('examples.conllu', 'w') as f_out:\n",
    "    f_out.write(convert_conll(\"Who died in 1285?\"))\n",
    "    f_out.write(convert_conll(\"Zhenjin\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import codecs\n",
    "from mosestokenizer import MosesDetokenizer\n",
    "from conllu import parse\n",
    "from rules import Question, AnswerSpan\n",
    "# import pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-20 15:45:07,942 WARNING toolwrapper.py   85: stdbuf was not found; communication with perl may hang due to stdio buffering.\n"
     ]
    }
   ],
   "source": [
    "detokenizer = MosesDetokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing conllu file...\n"
     ]
    }
   ],
   "source": [
    "print('Parsing conllu file...')\n",
    "with codecs.open('examples.conllu', 'r', encoding='utf-8') as f:\n",
    "    conllu_file = parse(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dict\n",
    "ids = range(int(len(conllu_file)/2))\n",
    "examples = {}\n",
    "count = 0\n",
    "for i, s in enumerate(conllu_file):\n",
    "    if i % 2 == 0:\n",
    "        examples[ids[count]] = s\n",
    "    else:\n",
    "        examples[str(ids[count])+'_answer'] = s\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa2d(idx):\n",
    "    print(list(examples[idx]))\n",
    "    q = Question(deepcopy(list(examples[idx])))\n",
    "    if not q.isvalid:\n",
    "        print(\"Question {} is not valid.\".format(idx))\n",
    "        return ''\n",
    "    a = AnswerSpan(deepcopy(list(examples[str(idx)+'_answer'])))\n",
    "    if not a.isvalid:\n",
    "        print(\"Answer span {} is not valid.\".format(idx))\n",
    "        return ''\n",
    "    q.insert_answer_default(a)\n",
    "    return detokenizer(q.format_declr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sentence(idx):\n",
    "    return detokenizer([list(examples[idx])[i]['form'] for i in range(len(list(examples[idx])))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming 1 examples.\n",
      "[{'id': 1, 'form': 'Who', 'lemma': 'who', 'upos': 'PRON', 'xpos': 'WP', 'feats': None, 'head': 2, 'deprel': 'nsubj', 'deps': None, 'misc': None}, {'id': 2, 'form': 'died', 'lemma': 'die', 'upos': 'VERB', 'xpos': 'VBD', 'feats': {'Tense': 'Past', 'VerbForm': 'Fin'}, 'head': 0, 'deprel': 'root', 'deps': None, 'misc': None}, {'id': 3, 'form': 'in', 'lemma': 'in', 'upos': 'ADP', 'xpos': 'IN', 'feats': None, 'head': 2, 'deprel': 'prep', 'deps': None, 'misc': None}, {'id': 4, 'form': '1285', 'lemma': '1285', 'upos': 'NUM', 'xpos': 'CD', 'feats': {'NumType': 'Card'}, 'head': 3, 'deprel': 'pobj', 'deps': None, 'misc': None}, {'id': 5, 'form': '?', 'lemma': '?', 'upos': 'PUNCT', 'xpos': '.', 'feats': {'PunctType': 'Peri'}, 'head': 2, 'deprel': 'punct', 'deps': None, 'misc': None}]\n",
      "Who died in 1285?\n",
      "Zhenjin died in 1285.\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "total = int(len(examples.keys())/2)\n",
    "print(\"Transforming {} examples.\".format(total))\n",
    "for i in range(total):\n",
    "    out = qa2d(i)\n",
    "    print(print_sentence(i))\n",
    "    if out != '':\n",
    "        print(out)\n",
    "    print('----------')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'form': 'Who',\n",
       "  'lemma': 'who',\n",
       "  'upos': 'PRON',\n",
       "  'xpos': 'WP',\n",
       "  'feats': None,\n",
       "  'head': 2,\n",
       "  'deprel': 'nsubj',\n",
       "  'deps': None,\n",
       "  'misc': None},\n",
       " {'id': 2,\n",
       "  'form': 'died',\n",
       "  'lemma': 'die',\n",
       "  'upos': 'VERB',\n",
       "  'xpos': 'VBD',\n",
       "  'feats': {'Tense': 'Past', 'VerbForm': 'Fin'},\n",
       "  'head': 0,\n",
       "  'deprel': 'root',\n",
       "  'deps': None,\n",
       "  'misc': None},\n",
       " {'id': 3,\n",
       "  'form': 'in',\n",
       "  'lemma': 'in',\n",
       "  'upos': 'ADP',\n",
       "  'xpos': 'IN',\n",
       "  'feats': None,\n",
       "  'head': 2,\n",
       "  'deprel': 'prep',\n",
       "  'deps': None,\n",
       "  'misc': None},\n",
       " {'id': 4,\n",
       "  'form': '1285',\n",
       "  'lemma': '1285',\n",
       "  'upos': 'NUM',\n",
       "  'xpos': 'CD',\n",
       "  'feats': {'NumType': 'Card'},\n",
       "  'head': 3,\n",
       "  'deprel': 'pobj',\n",
       "  'deps': None,\n",
       "  'misc': None},\n",
       " {'id': 5,\n",
       "  'form': '?',\n",
       "  'lemma': '?',\n",
       "  'upos': 'PUNCT',\n",
       "  'xpos': '.',\n",
       "  'feats': {'PunctType': 'Peri'},\n",
       "  'head': 2,\n",
       "  'deprel': 'punct',\n",
       "  'deps': None,\n",
       "  'misc': None}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def get_tokens(token_list):\n",
    "#     return [t['form'] for t in list(token_list)]\n",
    "\n",
    "# get_tokens(examples[0])\n",
    "\n",
    "list(examples[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36425f52c2d70ca35494b09c6a43fbe531c1a31a7612b4fb43fd3685ca29a299"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
